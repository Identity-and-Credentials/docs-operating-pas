---
title: Getting Started with Small Footprint TAS for VMs
owner: RelEng
---

The Small Footprint <%= vars.app_runtime_abbr %> is a repackaging of the <%= vars.app_runtime_abbr %> components into a
smaller deployment with fewer virtual machines (VMs). For a description of the limitations that come with a
smaller deployment, see [Limitations](#limits).

## <a id='compare'></a> Differentiate small footprint <%= vars.app_runtime_abbr %> and <%= vars.app_runtime_abbr %>

A standard <%= vars.app_runtime_abbr %> deployment must have at least 13 VMs, but Small Footprint <%= vars.app_runtime_abbr %> requires only four.


* Required VMs: Cloud Controller, Cloud Controller Worker, Clock Global, Diego BBS, Diego Brain, Diego Cell, Doppler Server, Loggregator Traffic Controller, NATS, Router, Syslog Adapter, Syslog Scheduler, and UAA.
* Optional VMs: File Storage, HAProxy, Backup Restore Node, MySQL Monitor, MySQL Proxy, MySQL Server, TCP Router, and CredHub.

For Small Footprint TAS for VMs:

* Required VMs: Compute, Control, Database, and Router.
* Optional VMs: File Storage, HAProxy, Backup Restore Node, MySQL Monitor, and TCP Router.

The following image displays a comparison of the number of VMs deployed by <%= vars.app_runtime_abbr %> and Small Footprint <%= vars.app_runtime_abbr %>.
For TAS for VMs:

[//]: https://docs.google.com/drawings/d/19V1SY4BGW2T--c4Y8Jm26CkA8C-6jIHXl7gpEzYlTmY/edit?usp=sharing

![alt-text=""](./images/ert-vms-2.0.png)

## <a id='install'></a> Installing Small Footprint <%= vars.app_runtime_abbr %>

To install Small Footprint <%= vars.app_runtime_abbr %>, see [Architecture and Installation Overview](https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/3.0/vmware-tanzu-ops-manager/refarch-index.html) and the installation and configuration topics for your IaaS.

Follow the same installation and configuration steps as for <%= vars.app_runtime_abbr %>, with these differences:

* **Selecting a product in <%= vars.product_network %>:** When you go to the [<%= vars.app_runtime_full %>](https://network.tanzu.vmware.com/products/elastic-runtime) page on <%= vars.product_network %>, select the **Small Footprint** release.

* **Configuring resources:**
	* The **Resource Config** pane in the Small Footprint <%= vars.app_runtime_abbr %> tile reflects the differences in VMs discussed in [Architecture](#arch).
	* Small Footprint <%= vars.app_runtime_abbr %> does not default to a highly available configuration like <%= vars.app_runtime_abbr %> does. It defaults to a minimum configuration. To make Small Footprint <%= vars.app_runtime_abbr %> highly available, scale the VMs to the following instance counts:
      * **Compute**: `3`
      * **Control**: `2`
      * **Database**: `3`
      * **Router**: `3`

* **Configuring load balancers:** If you are using an SSH load balancer, you must enter its name in the **Control VM** row of the **Resource Config** pane. There is no **Diego Brain** row in Small Footprint <%= vars.app_runtime_abbr %> because the Diego Brain is co-located on the Control VM. You can still enter the appropriate load balancers in the **Router** and **TCP Router** rows as normal.


## <a id='logs'></a> Troubleshooting co-located jobs using logs

To troubleshoot a job that runs on the Control or Database VMs:

1. Follow the procedures in _Advanced Troubleshooting with the BOSH CLI_ to  the log in to the BOSH Director for your deployment:
	1. [Gather Credential and IP Address Information](https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/3.0/vmware-tanzu-ops-manager/install-trouble-advanced.html#gather)
	2. [Log into <%= vars.ops_manager %> with SSH](https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/3.0/vmware-tanzu-ops-manager/install-trouble-advanced.html#ssh)
	3. [Authenticate with the BOSH Director](https://docs.vmware.com/en/VMware-Tanzu-Operations-Manager/3.0/vmware-tanzu-ops-manager/install-trouble-advanced.html#log-in)

2. Use BOSH to list the VMs in your Small Footprint <%= vars.app_runtime_abbr %> deployment. Run:

		bosh -e BOSH-ENV -d TAS-DEPLOYMENT vms

	Where:
	* `BOSH-ENV` is the name of your BOSH environment.
	* `TAS-DEPLOYMENT` is the name of your Small Footprint <%= vars.app_runtime_abbr %> deployment.

	<p> If you do not know the name of your deployment, you can run
		<code>bosh -e BOSH-ENV deployments</code> to list the deployments for your BOSH Director.</p>

3. Use BOSH to SSH into one of the Small Footprint <%= vars.app_runtime_abbr %> VMs. Run:

		bosh -e BOSH-ENV -d TAS-DEPLOYMENT ssh VM-NAME/VM-GUID

	Where:
	* `BOSH-ENV` is the name of your BOSH environment.
	* `TAS-DEPLOYMENT` is the name of your Small Footprint <%= vars.app_runtime_abbr %> deployment.
	* `VM-NAME` is the name of your VM.
	* `VM-GUID` is the GUID of your VM.

	For example, to SSH into the Control VM, run:

		bosh -e example-env -d example-deployment ssh control/12b1b027-7ffd-43ca-9dc9-7f4ff204d86a

4. To act as a super user, run:

		sudo su

5. To list the processes running on the VM, run:

		monit summary

	The following example output lists the processes running on the Control VM. The processes listed reflect the co-location of jobs as outlined in [Architecture](#arch).
	<pre class="terminal">
	control/12b1b027-7ffd-43ca-9dc9-7f4ff204d86a:/var/vcap/bosh\_ssh/bosh\_f9d2446b18b445e# monit summary
	The Monit daemon 5.2.5 uptime: 5d 21h 10m

	Process 'bbs'                       running
	Process 'metron\_agent'              running
	Process 'locket'                    running
	Process 'route\_registrar'           running
	Process 'policy-server'             running
	Process 'silk-controller'           running
	Process 'uaa'                       running
	Process 'statsd\_injector'           running
	Process 'cloud\_controller\_ng'       running
	Process 'cloud\_controller\_worker\_local\_1' running
	Process 'cloud\_controller\_worker\_local\_2' running
	Process 'nginx\_cc'                  running
	Process 'routing-api'               running
	Process 'cloud\_controller\_clock'    running
	Process 'cloud\_controller\_worker\_1' running
	Process 'auctioneer'                running
	Process 'cc\_uploader'               running
	Process 'file\_server'               running
	Process 'nsync\_listener'            running
	Process 'ssh\_proxy'                 running
	Process 'tps\_watcher'               running
	Process 'stager'                    running
	Process 'loggregator\_trafficcontroller' running
	Process 'reverse\_log\_proxy'         running
	Process 'adapter'                   running
	Process 'doppler'                   running
	Process 'syslog\_drain\_binder'       running
	System 'system\_localhost'           running
	</pre>

6. To access logs, go to `/vars/vcap/sys/log` by running:

		cd /var/vcap/sys/log

7. To list the log directories for each process, run:

		ls

8. Go to the directory of the process that you want to view logs for. For example, for the Cloud Controller process, run:

		cd cloud_controller_ng/

	From the directory of the process, you can list and view its logs. See the following example output:
	<pre class="terminal">
	control/12b1b027-7ffd-43ca-9dc9-7f4ff204d86a:/var/vcap/sys/log/cloud\_controller\_ng# ls
	cloud\_controller\_ng\_ctl.err.log  cloud\_controller\_ng.log.2.gz  cloud\_controller\_ng.log.6.gz         drain                  pre-start.stdout.log
	cloud\_controller\_ng\_ctl.log      cloud\_controller\_ng.log.3.gz  cloud\_controller\_ng.log.7.gz         post-start.stderr.log
	cloud\_controller\_ng.log          cloud\_controller\_ng.log.4.gz  cloud\_controller\_worker\_ctl.err.log  post-start.stdout.log
	cloud\_controller\_ng.log.1.gz     cloud\_controller\_ng.log.5.gz  cloud\_controller\_worker\_ctl.log      pre-start.stderr.log
	</pre>
